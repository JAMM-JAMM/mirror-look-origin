# -*- coding: utf-8 -*-
"""DeepFashionModelVGG16.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1dIVk--Hl-eBgKPmJpt68zZ8PTl5gVAtn
"""

from tensorflow.keras.applications import vgg16
from keras.applications.vgg16 import VGG16
import keras
from keras.layers import Conv2D,Dense,MaxPooling2D,Dropout,Flatten, Activation, BatchNormalization,LeakyReLU
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import pandas as pd
import cv2
import glob
from keras.utils import plot_model

# DeepFashion Dataset Path
train_path = '/home/azure/passion/AI/Category and Attribute Prediction Benchmark/dataset/train'
validation_path = '/home/azure/passion/AI/Category and Attribute Prediction Benchmark/dataset/validation'

# Setting the Parameters & Hyperparameters
img_row, img_col, img_channel = 224, 224, 3
batch_size_train = 32
batch_size_validation = 32
epochs = 10
category_nums = 50
drop_rate = 0.25
learning_rate = 0.001
momentum_num = 0.99
plot_num_rows = 3
plot_num_rows = 3

# Initialize the VGG model
vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(img_row, img_col, img_channel))

# Freeze all the layers
for layer in vgg_conv.layers[:]:
    layer.trainable = False

# Check the trainable status of the individual layers
for layer in vgg_conv.layers:
    print(layer, layer.trainable)

# Creating the model Architecture
def build_model(vgg_conv, category_nums, drop_rate, learning_rate, momentum_num):

    # Create the model
    model = keras.models.Sequential()

    # Add the vgg convolutional base model
    model.add(vgg_conv)

    # Add new layers
    model.add(Flatten())
    model.add(Dense(1024, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(drop_rate))
    model.add(Dense(category_nums, activation='softmax'))

    # Compile the model with a SGD and a very slow learning rate
    model.compile(
        loss='binary_crossentropy',
        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
        metrics=['accuracy']
    )

    return model

model = build_model(vgg_conv, category_nums, drop_rate, learning_rate, momentum_num)

# Show a summary of the model
# plot_model(model, to_file='/home/azure/passion/AI/Category and Attribute Prediction Benchmark/dataset/plot/model_summary.jpg')

# Data Load
def data_load(train_path, validation_path, batch_size_train, batch_size_validation, img_row, img_col):

    # Train
    imgdatagen_train = ImageDataGenerator(
        rescale=1./255
    )

    train_dataset = imgdatagen_train.flow_from_directory(
        train_path,
        target_size=(img_row, img_col),
        batch_size=batch_size_train,
        classes = ['Anorak', 'Blazer', 'Blouse', 'Bomber', 'Button-Down', 'Cardigan', 'Flannel', 'Halter', 'Henley', 'Hoodie', 'Jacket', 'Jersey', 'Parka', 'Peacoat', 'Poncho', 'Sweater', 'Tank', 'Tee', 'Top', 'Turtleneck', 'Capris', 'Chinos', 'Culottes', 'Cutoffs', 'Gauchos', 'Jeans', 'Jeggings', 'Jodhpurs', 'Joggers', 'Leggings', 'Sarong', 'Shorts', 'Skirt', 'Sweatpants', 'Sweatshorts', 'Trunks', 'Caftan', 'Cape', 'Coat', 'Coverup', 'Dress', 'Jumpsuit', 'Kaftan', 'Kimono', 'Nightdress', 'Onesie', 'Robe', 'Romper', 'Shirtdress', 'Sundress'],
        shuffle=True
    )

    # Validation
    imgdatagen_validatioin = ImageDataGenerator(
        rescale=1./255
    )

    validation_dataset = imgdatagen_validatioin.flow_from_directory(
        validation_path,
        target_size=(img_row, img_col),
        batch_size=batch_size_validation,
        classes = ['Anorak', 'Blazer', 'Blouse', 'Bomber', 'Button-Down', 'Cardigan', 'Flannel', 'Halter', 'Henley', 'Hoodie', 'Jacket', 'Jersey', 'Parka', 'Peacoat', 'Poncho', 'Sweater', 'Tank', 'Tee', 'Top', 'Turtleneck', 'Capris', 'Chinos', 'Culottes', 'Cutoffs', 'Gauchos', 'Jeans', 'Jeggings', 'Jodhpurs', 'Joggers', 'Leggings', 'Sarong', 'Shorts', 'Skirt', 'Sweatpants', 'Sweatshorts', 'Trunks', 'Caftan', 'Cape', 'Coat', 'Coverup', 'Dress', 'Jumpsuit', 'Kaftan', 'Kimono', 'Nightdress', 'Onesie', 'Robe', 'Romper', 'Shirtdress', 'Sundress'],
        shuffle=True
    )

    return train_dataset, validation_dataset

train_dataset, validation_dataset = data_load(train_path, validation_path, batch_size_train, batch_size_validation, img_row, img_col)

X_train, y_train = next(train_dataset)

# print(X_train.shape)
# print(y_train.shape)

# Register Callbacks


# Fine-tune the model - Training
def fit_model(model, train_dataset, validation_dataset, batch_size_train, batch_size_validation, epochs):

    history = model.fit(
        train_dataset,
        epochs=epochs,
        validation_data=validation_dataset,
        workers=0,
        verbose=1
    )

    score = model.evaluate(
        validation_dataset,
        verbose=1
    )

    return model, history, score

model, history, score = fit_model(model, train_dataset, validation_dataset, batch_size_train, batch_size_validation, epochs)

# Plotting Accuracy & Loss Curves
def curves(model_histories, epochs):

    acc = model_histories.history['accuracy']
    val_acc = model_histories.history['val_accuracy']
    loss = model_histories.history['loss']
    val_loss = model_histories.history['val_loss']

    # Plot
    plt.plot(range(epochs), acc, 'mo', label='Training accuracy')
    plt.plot(range(epochs), val_acc, 'b', label='Validation accuracy')
    plt.title('Training and validation accuracy')
    plt.legend()
    plt.savefig('/home/azure/passion/AI/Category and Attribute Prediction Benchmark/dataset/plot/DeepFashionVGG16CurvesAcc.jpg')

    plt.figure()
    plt.plot(range(epochs), loss, 'mo', label='Training loss')
    plt.plot(range(epochs), val_loss, 'b', label='Validation loss')
    plt.title('Training and validation loss')
    plt.legend()
    plt.savefig('/home/azure/passion/AI/Category and Attribute Prediction Benchmark/dataset/plot/DeepFashionVGG16CurvesLoss.jpg')
    plt.show()

# Learning curves
curves(history, epochs)

print('Accuracy:{} \nLoss:{}'.format(score[1] ,score[0]))
